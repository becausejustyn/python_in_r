---
title: "R Notebook"
output: html_notebook
---

```{python}
def sigmoid(x):
  return(1/(1 + np.exp(-x)))
```

```{r}
sigmoid <- function(x) {
  return(1/(1 + exp(-x)))
}
```

```{python}
x = np.linspace(-6, 6)
y = sigmoid(x)

plt.plot(x, y, color="skyblue")
plt.xlabel("$x$"); plt.ylabel("$S(x)$")
plt.show()
```

```{r}
x <- seq(-6, 6)
y <- sigmoid(x)

plot(x, y, xlab = "$x$", ylab = "$S(x)$")
```

```{python}
toy_dataset = [[2.7810836,2.550537003,1],
           [1.465489372,2.362125076,1],
           [3.396561688,4.400293529,1],
           [1.38807019,1.850220317,1],
           [3.06407232,3.005305973,1],
           [7.627531214,2.759262235,1],
           [5.332441248,2.088626775,1],
           [6.922596716,1.77106367,1],
           [8.675418651,-0.242068655,1],
           [7.673756466,3.508563011,1]]
label = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
```

```{r}
toy_dataset <- c(
  2.7810836, 2.550537003, 1,
  1.465489372, 2.362125076, 1,
  3.396561688, 4.400293529, 1,
  1.38807019, 1.850220317, 1,
  3.06407232, 3.005305973, 1,
  7.627531214, 2.759262235, 1,
  5.332441248, 2.088626775, 1,
  6.922596716, 1.77106367, 1,
  8.675418651, -0.242068655, 1,
  7.673756466, 3.508563011, 1
  )

label <- c(0, 0, 0, 0, 0, 1, 1, 1, 1, 1)
```

```{python}
def make_prediction(w, x, classify=False):
    z = sigmoid(np.dot(w, x))
    if classify:
        return int(z > 0.5)
    else:
        return z
```

```{r}
make_prediction <- function(w, x, classify = FALSE) {
  z = sigmoid(w%*%x) 
  if (classify == TRUE) return(int > 0.5)
  if (classify == FALSE) return(z)
}
```

```{python}
weight = [-0.4, 0.9, -2]
prediction = []

for data in toy_dataset:
    prediction.append(
      make_prediction(
        weight, data, classify = True
        ))
        
prediction
```

```{r}
weight <- c(-0.4, 0.9, -2)
prediction <- c()

for(data in toy_dataset) {
  prediction <- make_prediction(
    weight, data, classify = TRUE
    )
}
    
prediction
```


```{python}
label
```

```{r}
label
```

```{python}
def cross_entropy(y_true, y_pred):
    data_num = len(y_true)
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    total = - np.sum(
      np.multiply(y_true, np.log(y_pred)) + np.multiply((1 - y_true), np.log(1 - y_pred)))
    return total / data_num
```

```{r}
cross_entropy <- function(y_true, y_pred) {
  data_num = length(y_true)
  y_true = as.array(y_true)
  y_pred = as.array(y_pred)
  total = - sum(
    (y_true * log(y_pred)) + ((1 - y_true) * log(1 - y_pred)))
    return(total / data_num)
}
```


```{python}
def gradient_descent(alpha, epoch, weight, X, y, threshold, print_option=True, get_cost=False):
    y_pred = np.array([make_prediction(weight, x) for x in X])
    data_num = len(y)
    cost = []
    for i in range(epoch):
        dw = np.dot((y_pred - y), X) / data_num
        weight = weight - alpha * dw
        y_pred = np.array([make_prediction(weight, x) for x in X])
        new_cost = cross_entropy(y, y_pred)
        cost.append(new_cost)
        if print_option and i%50==0: print("Iteration {0}, Cost: {1}".format(i, new_cost))
        if i > 3 and cost[-2] - cost[-1] < threshold:
            break
    if get_cost:
        return cost
    else:
        return weight
```

```{python}
gradient_descent(0.1, 200, weight, toy_dataset, label, 0.0001)
```


```{python}
def logistic_regression(training_set, label, test_set, alpha, epoch, threshold = 0.0001, print_option = False, get_cost = False):
    weight = np.random.rand(len(training_set[0]))
    if get_cost:
        cost = gradient_descent(
          alpha, epoch, weight, training_set, label, threshold, print_option, get_cost)
        return cost
    else:
        new_weight = gradient_descent(
          alpha, epoch, weight, training_set, label, threshold, print_option)
        prediction = [make_prediction(
          new_weight, instance, classify = True) for instance in test_set]
        return np.array(prediction)
```

```{python}
from numpy import loadtxt
from urllib.request import urlopen
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt'
raw_data = urlopen(url)
dataset = loadtxt(raw_data, delimiter=",")
X, y = np.array([np.append(x, 1) for x in dataset[:,:-1]]), dataset[:, -1]
```

```{python}
X.shape
y.shape
```

```{python}
def my_train_test_split(X, y, test_size, random_state):
    data_num = len(y)
    test_num = int(test_size * data_num)
    np.random.seed(random_state)
    index = np.random.permutation(data_num)
    X_train = X[index[:-test_num]]
    X_test = X[index[-test_num:]]
    y_train = y[index[:-test_num]]
    y_test = y[index[-test_num:]]
    return X_train, X_test, y_train, y_test
```

```{python}
X_train, X_test, y_train, y_test = my_train_test_split(X, y, 0.2, 42)
```

```{python}
y_pred = logistic_regression(X_train, y_train, X_test, 0.1, 1000, threshold=0.00001, print_option=True)
```

```{python}
dictionary = {}
for boolean in y_pred == y_test:
  if boolean in dictionary:
    dictionary[boolean] += 1
  else:
    dictionary[boolean] = 1
  
dictionary
```

```{python}
def accuracy_score(y_true, y_pred):
    count = 0
    for true, pred in zip(y_true, y_pred):
        if true == pred:
            count += 1
    return count/len(y_true)
```

```{python}
accuracy_score(y_pred, y_test)
```

```{python}
def plot_accuracy(alpha, epoch):
    accuracy = []
    iter_range = range(epoch)
    for iter_num in iter_range:
        y_hat = logistic_regression(X_train, y_train, X_test, alpha, iter_num)
        accuracy.append(accuracy_score(y_hat, y_test))
    plt.plot(iter_range, accuracy, color="skyblue")
    plt.xlabel("Epochs"); plt.ylabel("Accuracy")
    plt.show()
```

```{python}
plot_accuracy(0.1, 200)
```

```{python}
plot_accuracy(0.01, 200)
```

```{python}
def plot_loss(alpha, epoch):
    for rate in alpha:
        cost = logistic_regression(X_train, y_train, X_test, rate, epoch, threshold=0.00001, get_cost=True)
        iter_num = range(len(cost))
        plt.scatter(iter_num, cost, label=r'$\alpha$ = {0}'.format(rate))
    plt.xlabel("Number of Iterations"); plt.ylabel("Cross Entropy Loss")
    plt.legend()
    plt.show()
```

```{python}
epoch = 200
alpha_lst = [0.05, 0.1, 0.5]
plot_loss(alpha_lst, epoch)
```

```{python}

```

```{python}

```

```{python}

```
